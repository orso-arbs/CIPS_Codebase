import numpy as np
from cellpose import utils, io
import glob
import os
import pandas as pd
import math
from skimage import io as sk_io, color
import re
import pickle


import sys
import os
import Format_1 as F_1

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)






@F_1.ParameterLog(max_size = 1024 * 10, log_level = 0) # 0.1KB per smallest unit in return (8 bits per ASCII character)
def CP_extract_1(
    # input
    input_dir,

    # extraction parameters
    diameter_training_px = None, # specific override for diameter_training_px
    save_flows = 0, # 0: don't save flows, 1: save flows

    # output and logging 
    CP_extract_log_level = 0,
    output_dir_manual = "", output_dir_comment = "",
    ):
    
    """
    Extracts segmentation data and calculates pixel-based metrics, saving the
    results to a pandas DataFrame.

    This function processes Cellpose segmentation output files (`_seg.npy`)
    located in the `input_dir`. It loads corresponding image data, VisIt projection
    data, and Cellpose settings. It then calculates various pixel-based metrics
    like cell counts, diameters (mean, median, distribution), and areas.
    Finally, all extracted and calculated data is compiled into a pandas DataFrame
    named 'extracted_DataFrame' and saved in CSV, Pickle, and Excel formats
    in the specified output directory. This DataFrame serves as input for the
    `CP_dimentionalise_1` function.

    Parameters
    ----------
    input_dir : str
        Path to the directory containing the Cellpose segmentation output files
        (`*_seg.npy`) and the `CP_settings.pkl` file generated by `CP_segment_1`.
    diameter_training_px : float or None, optional
        The diameter (in pixels) that was used during the training of the Cellpose
        segmentation model. If provided, this value overrides any value found in
        `CP_settings.pkl`. If None, the value is taken from `CP_settings.pkl`.
        If also not found in settings, it's deduced from the segmentation model type
        (for standard models like 'cyto', 'cyto2', 'cyto3', 'nuclei').
        Defaults to None.
    CP_extract_log_level : int, optional
        Controls the verbosity of logging messages printed to the console.
        0: Minimal logging.
        1: Basic loading and processing steps.
        Defaults to 0.
    output_dir_manual : str, optional
        If provided, specifies the exact output directory path. Overrides the
        default naming convention managed by `Format_1.F_out_dir`. Defaults to "".
    output_dir_comment : str, optional
        A comment to append to the default output directory name if `output_dir_manual`
        is not provided. Defaults to "".

    Returns
    -------
    output_dir : str
        The path to the directory where the output DataFrame files
        (`extracted_DataFrame.csv`, `extracted_DataFrame.pkl`,
        `extracted_DataFrame.xlsx`) and logs (`_log.json`) are saved.
        This is always the first return value as required by Format_1.

    Notes
    -----
    - This function relies on `Format_1.py` for output directory creation (`F_out_dir`)
      and parameter logging (`@F_1.ParameterLog`).
    - Assumes the input directory (`input_dir`) is a subdirectory of the directory
      containing the original images (`.png`) and the VisIt data (`Visit_projector_1_data.pkl`).
    """
    #################################################### I/O
    output_dir = F_1.F_out_dir(input_dir, __file__, output_dir_comment = output_dir_comment, output_dir_manual = output_dir_manual) # Format_1 required definition of output directory



    #################################################### Load and extract data
    print(f"\n Loading data \n")


    # Load VisIt data (VisIt data not images)
    VisIt_output_dir = os.path.abspath(os.path.join(input_dir, os.pardir))
    VisIt_data_dir = f"{VisIt_output_dir}\Visit_projector_1_data.pkl"
    VisIt_data_df = pd.read_pickle(VisIt_data_dir)
    print(f"VisIt_output_dir: {VisIt_output_dir}") if CP_extract_log_level >= 2 else None
    print(f"VisIt_data_dir: {VisIt_data_dir}") if CP_extract_log_level >= 2 else None
    print(f"VisIt_data: {VisIt_data_df}") if CP_extract_log_level >= 2 else None

    # Load image data (could be VisIt output images)
    image_input_dir = os.path.dirname(input_dir) # one folder above
    image_files = glob.glob(os.path.join(image_input_dir, '*.png'))
    all_images = []
    all_grayscale_images = []
    image_number = []
    for image_file in image_files:
        # Load the image (RGBA)
        rgbA_image_px2 = sk_io.imread(image_file)
        
        # Convert to grayscale by ignoring the alpha channel
        grayscale_image = color.rgb2gray(rgbA_image_px2[..., :3])
        
        # Append both RGBA and grayscale images as a tuple
        all_images.append(rgbA_image_px2)
        all_grayscale_images.append(grayscale_image)

        # Extract the numeric part from the filename
        match = re.search(r'_(\d+)\.png$', os.path.basename(image_file))
        if match:
            image_number.append(int(match.group(1)))
        else:
            image_number.append(None)  # Handle cases where no number is found

    N_images = len(all_images)
    print(f"Loaded {N_images} images \n") if CP_extract_log_level >= 1 else None

    # Load Cellpose segmentation data
    seg_location = input_dir
    seg_files = glob.glob(os.path.join(seg_location, '*_seg.npy'))
    all_segs = []
    seg_filenames = []
    for seg_file in seg_files:
        seg = np.load(seg_file, allow_pickle=True).item()
        all_segs.append(seg)
        filename = os.path.basename(seg_file).replace('_seg.npy', '')
        seg_filenames.append(filename)
        #print(f"Adding file to all_segs: {seg_file}")  # Print the file being added
    N_seg = len(all_segs)
    print(f"Loaded {N_seg} seg files") if CP_extract_log_level >= 1 else None
    if N_images != N_seg:
        raise ValueError("Number of images and segmentations do not match")


    # Load Cellpose model settings
    CP_settings_file = f"{input_dir}/CP_settings.pkl"
    with open(CP_settings_file, "rb") as file:
        CP_settings = pickle.load(file)
        # Load with .get() and provide a default Series to safely use .iloc[0]
        # This handles cases where keys might be missing in older settings files.
        CP_model_type_for_segmentation_val = CP_settings.get("CP_model_type_for_segmentation", pd.Series([None])).iloc[0]
        CP_segmentation_model_actual_path_val = CP_settings.get("CP_segmentation_model_actual_path", pd.Series([None])).iloc[0]
        CP_model_type_for_diameter_estimation_input_val = CP_settings.get("CP_model_type_for_diameter_estimation_input", pd.Series([None])).iloc[0]
        CP_size_model_type_in_wrapper_val = CP_settings.get("CP_size_model_type_in_wrapper", pd.Series([None])).iloc[0]
        
        diam_train_px_settings_series = CP_settings.get("diameter_training_px", pd.Series([None]))
        diameter_training_px_from_settings = None
        if diam_train_px_settings_series.iloc[0] is not None:
            if isinstance(diam_train_px_settings_series.iloc[0], np.ndarray) and len(diam_train_px_settings_series.iloc[0]) > 0:
                diameter_training_px_from_settings = diam_train_px_settings_series.iloc[0][0] # Get scalar from array
            elif isinstance(diam_train_px_settings_series.iloc[0], (int, float)): # If it's already a scalar
                 diameter_training_px_from_settings = diam_train_px_settings_series.iloc[0]


        # Other settings (ensure robust loading if they could be missing)
        gpu = CP_settings.get("gpu", pd.Series([True])).iloc[0] # Default to True if missing
        diameter_estimate_guess_px = CP_settings.get("diameter_estimate_guess_px", pd.Series([None])).iloc[0]
        CP_segment_output_dir_comment = CP_settings.get("CP_segment_output_dir_comment", pd.Series([""])).iloc[0]
        flow_threshold = CP_settings.get("flow_threshold", pd.Series([0.4])).iloc[0] # Default based on Cellpose
        cellprob_threshold = CP_settings.get("cellprob_threshold", pd.Series([0.0])).iloc[0] # Default based on Cellpose
        resample = CP_settings.get("resample", pd.Series([True])).iloc[0] # Default based on Cellpose
        niter = CP_settings.get("niter", pd.Series([0])).iloc[0] # Default based on Cellpose

    print(f"CP_settings_file: {CP_settings_file}") if CP_extract_log_level >= 2 else None
    print(f"CP_settings: {CP_settings}") if CP_extract_log_level >= 2 else None


    # Determine the final diameter_training_px to use
    # Priority: 1. Function argument, 2. From CP_settings.pkl, 3. Deduced from model type
    final_diameter_training_px = diameter_training_px # From function argument

    if final_diameter_training_px is None:
        final_diameter_training_px = diameter_training_px_from_settings
    
    if final_diameter_training_px is None:
        # Fallback logic using the segmentation model type loaded from settings
        if CP_model_type_for_segmentation_val in ["cyto", "cyto2", "cyto3"]:
            final_diameter_training_px = 30.0
        elif CP_model_type_for_segmentation_val == "nuclei":
            final_diameter_training_px = 17.0
        else: # Covers custom models or if CP_model_type_for_segmentation_val is None or not a standard type
            print("NB: diameter_training_px could not be determined from function arguments, CP_settings.pkl, or standard model types. It will be set to None.")
            # final_diameter_training_px remains None


    #################################################### Extract and Tabularize data

    print(f"\n Extracting data \n")

    # Initialize DataFrame
    extracted_df_columns = [
        'image_file_name', 'image_file_path', 'image_number', 'image_Nx_px', 'image_Ny_px',
        'seg_file_name', 'seg_file_path', 'ismanual', 
        'CP_segmentation_model_actual_path', 'CP_model_type_for_segmentation', 
        'CP_model_type_for_diameter_estimation_input', 'CP_size_model_type_in_wrapper', 
        'channels',
        'flows0', 'flows1', 'flows2', 'flows3', 'flows4',
        'diameter_estimate_used_px', 'diameter_training_px',
        'CP_out_diameter_mean_px', 'CP_out_diameter_median_px', 'CP_out_diameter_distribution_px', 'outlines', 'masks', 'N_cells',
        'A_image_px2', 'A_empty_px2', 'A_SF_px2', 'Ar_px2_SFperimage', 'D_SF_px', 'R_SF_px',
        'A_CP_mask_px2', 'Ar_px2_CP_maskperImage', 'Ar_px2_CP_maskperSF',
        # Add cell-wise metrics columns
        'A_cell_distribution_px2', 'd_cell_distribution_px',
        'centroid_x_distribution_px', 'centroid_y_distribution_px',
        'd_cell_mean_px', 'A_cell_mean_px2',
        'd_cell_median_px', 'A_cell_median_px2',  # Add new columns
        # Added columns from CP_settings that were previously read but not explicitly added here
        'gpu', 'diameter_estimate_guess_px', 'CP_segment_output_dir_comment', 'flow_threshold',
        'cellprob_threshold', 'resample', 'niter'
    ]
    extracted_df = pd.DataFrame(columns=extracted_df_columns)

    # Preallocate columns to avoid growing the DataFrame dynamically
    for col in extracted_df_columns:
        extracted_df[col] = np.nan  # Initialize all columns with NaN

    # Explicitly set multiple columns to 'object' to allow lists or complex data types
    columns_with_lists = [
        # Cellpose settings and outputs
        'ismanual', 'flows0', 'flows1', 'flows2', 'flows3', 'flows4', 'channels',
        'outlines', 'masks', 'CP_out_diameter_distribution_px',
        # cell-wise metrics 
        'A_cell_distribution_px2', 'd_cell_distribution_px',
        'centroid_x_distribution_px', 'centroid_y_distribution_px'
    ]
    for column in columns_with_lists:
        # Check if column exists before setting dtype, as some might be added later
        if column in extracted_df.columns:
            extracted_df[column] = pd.Series(dtype="object")

    # Ensure all columns intended to be object are explicitly set, even if pre-allocated differently
    for col in columns_with_lists:
        if col in extracted_df.columns:
            extracted_df[col] = extracted_df[col].astype('object')


    ## Extract data by looping through each image and its segmentation
    print()
    for i in range(N_images):
        # Add debug print to track which image is being processed
        print(f"\rProcessing image {i+1}/{N_images} (filename: {os.path.basename(image_files[i])})", end='', flush=True) if CP_extract_log_level >= 1 else None
        
        image_i = all_images[i]
        grayscale_image_i = all_grayscale_images[i]
        
        # Verify the segmentation file exists and can be accessed
        if i >= len(all_segs):
            print(f"WARNING: Missing segmentation for image {i}") if CP_extract_log_level >= 1 else None
            continue
            
        seg_i = all_segs[i]

        # read seg
        masks_i = seg_i['masks']
        outlines_i = seg_i['outlines']
        if save_flows == 1: # to save storage space don't save flows values.
            flow_i = seg_i['flows']
        else:
            flow_i = [None] * 5
        diameter_estimate_used_px_i = seg_i["diameter"]
        channels = seg_i["chan_choose"]
        ismanual = seg_i['ismanual']
        seg_image_filename = seg_i["filename"] # gives seg filename though it shoud give images file name. weird...
        N_cells_i = np.max(masks_i)

        # diameter_training_px is now determined outside the loop as final_diameter_training_px

        # Check if there are any cells first
        if N_cells_i == 0:
            CP_out_diameter_median_px_i = np.nan
            CP_out_diameter_array_px_i = np.array([])
            CP_out_diameter_mean_px_i = np.nan
        else:
            # extract diameter tuple and from its mean and complete distribution from Cellpose output
            CP_out_diameters_tuple_i = utils.diameters(masks_i)
            CP_out_diameter_median_px_i = CP_out_diameters_tuple_i[0]
            CP_out_diameter_array_px_i = CP_out_diameters_tuple_i[1]
            CP_out_diameter_mean_px_i = np.mean(CP_out_diameter_array_px_i)

        # Calculate the relative frequency of each diameter in CP_out_diameter_array_px_i
        if len(CP_out_diameter_array_px_i) == 0:
            diameters_unique = np.array([])
            diameters_relative_frequencies = np.array([])
            diameters_total = 0
        else:
            diameters_unique, counts_diameters = np.unique(CP_out_diameter_array_px_i, return_counts=True)
            diameters_total = CP_out_diameter_array_px_i.size
            diameters_relative_frequencies = counts_diameters / diameters_total

        # CP effectiveness measures
        image_Nx_px = image_i.shape[0]
        image_Ny_px = image_i.shape[1]
        A_image_px2 = image_Nx_px * image_Ny_px
        A_empty_px2 = np.sum(grayscale_image_i == 1)
        A_SF_px2 = A_image_px2 - A_empty_px2
        Ar_px2_SFperimage = A_SF_px2 / A_image_px2
        D_SF_px = math.sqrt(A_SF_px2 * 4 / math.pi)
        R_SF_px = D_SF_px / 2

        A_CP_mask_px2 = np.count_nonzero(masks_i != 0)
        Ar_px2_CP_maskperImage = A_CP_mask_px2 / A_image_px2
        Ar_px2_CP_maskperSF = A_CP_mask_px2 / A_SF_px2
        
        ################### cell-wise metrics

        # Get unique cell IDs (excluding background = 0)##
        cell_ids = np.unique(masks_i)
        cell_ids = cell_ids[cell_ids > 0]  # Exclude background (ID=0)
        
        # Print progress update that overwrites itself
        if CP_extract_log_level >= 1:
            print(f" ({len(cell_ids)} cells found)", end='', flush=True)

        # Initialize cell property arrays - even if empty
        A_cell_distribution_px2 = []
        d_cell_distribution_px = []
        centroid_x_distribution_px = []
        centroid_y_distribution_px = []
        
        # If no cells found, set placeholder values but don't skip the image
        if len(cell_ids) == 0:
            d_cell_mean_px = np.nan
            A_cell_mean_px2 = np.nan
            d_cell_median_px = np.nan
            A_cell_median_px2 = np.nan
        else:
            # Process each cell in the image
            for cell_id in cell_ids:
                # Create a binary mask for this specific cell
                cell_mask = masks_i == cell_id
                
                # Calculate centroid of the cell
                y_coords, x_coords = np.where(cell_mask)
                if len(y_coords) == 0:
                    continue
                    
                # Find cell centroid in pixel coordinates
                centroid_y_px = np.mean(y_coords).astype(float)
                centroid_x_px = np.mean(x_coords).astype(float)
                
                # Calculate cell area in pixels^2
                A_cell_px2 = len(y_coords)
                
                # Calculate cell diameter in pixels using area
                d_cell_px = 2 * np.sqrt(A_cell_px2 / np.pi)
                            
                # Append values to respective lists
                A_cell_distribution_px2.append(A_cell_px2)
                d_cell_distribution_px.append(d_cell_px)
                centroid_x_distribution_px.append(centroid_x_px)
                centroid_y_distribution_px.append(centroid_y_px)
            
                print(f"Processed cell {cell_id}: "
                    f"length A_cell_distribution_px2={len(A_cell_distribution_px2)}, "
                    f"A_cell_distribution_px2={A_cell_distribution_px2[-1]}, ") if CP_extract_log_level >= 4 else None

            # Calculate mean and median diameter from the distributions
            # Make sure there are cells before calculating statistics
            if len(d_cell_distribution_px) > 0:
                d_cell_mean_px = np.mean(d_cell_distribution_px)
                A_cell_mean_px2 = np.mean(A_cell_distribution_px2)
                d_cell_median_px = np.median(d_cell_distribution_px)
                A_cell_median_px2 = np.median(A_cell_distribution_px2)
            else:
                d_cell_mean_px = np.nan
                A_cell_mean_px2 = np.nan
                d_cell_median_px = np.nan
                A_cell_median_px2 = np.nan

        # Ensure we always set an array value even if empty
        A_cell_distribution_px2 = np.array(A_cell_distribution_px2)
        d_cell_distribution_px = np.array(d_cell_distribution_px)
        centroid_x_distribution_px = np.array(centroid_x_distribution_px)
        centroid_y_distribution_px = np.array(centroid_y_distribution_px)

        # Fill DataFrame row with current image data
        # Data from VisIt
        extracted_df.at[i, 'Plot_VisIt']                            = VisIt_data_df.at[i, 'Plot_VisIt']
        extracted_df.at[i, 'Image_filename_VisIt']                  = VisIt_data_df.at[i, 'Image_filename_VisIt']
        extracted_df.at[i, 'State_range_VisIt']                     = VisIt_data_df.at[i, 'State_range_VisIt']
        extracted_df.at[i, 'Time_VisIt']                            = VisIt_data_df.at[i, 'Time_VisIt']
        extracted_df.at[i, 'R_SF_Average_VisIt']                    = VisIt_data_df.at[i, 'R_SF_Average_VisIt']
        extracted_df.at[i, 'Min_Psuedocolored_variable_SF_VisIt']   = VisIt_data_df.at[i, 'Min_Psuedocolored_variable_SF_VisIt']
        extracted_df.at[i, 'Max_Psuedocolored_variable_SF_VisIt']   = VisIt_data_df.at[i, 'Max_Psuedocolored_variable_SF_VisIt']
        # Data from Images
        extracted_df.at[i, 'image_file_name'] = os.path.basename(image_files[i]) # Store only filename
        extracted_df.at[i, 'image_file_path'] = image_files[i]
        extracted_df.at[i, 'image_number'] = image_number[i]
        extracted_df.at[i, 'image_Nx_px'] = image_Nx_px
        extracted_df.at[i, 'image_Ny_px'] = image_Ny_px
        # Data from Cellpose settings
        extracted_df.at[i, 'CP_segmentation_model_actual_path'] = CP_segmentation_model_actual_path_val
        extracted_df.at[i, 'CP_model_type_for_segmentation'] = CP_model_type_for_segmentation_val
        extracted_df.at[i, 'CP_model_type_for_diameter_estimation_input'] = CP_model_type_for_diameter_estimation_input_val
        extracted_df.at[i, 'CP_size_model_type_in_wrapper'] = CP_size_model_type_in_wrapper_val
        extracted_df.at[i, 'channels'] = channels
        extracted_df.at[i, 'gpu'] = gpu
        extracted_df.at[i, 'diameter_estimate_guess_px'] = diameter_estimate_guess_px
        extracted_df.at[i, 'CP_segment_output_dir_comment'] = CP_segment_output_dir_comment
        extracted_df.at[i, 'flow_threshold'] = flow_threshold
        extracted_df.at[i, 'cellprob_threshold'] = cellprob_threshold
        extracted_df.at[i, 'resample'] = resample
        extracted_df.at[i, 'niter'] = niter
        # Data from seg file
        extracted_df.at[i, 'seg_file_name'] = seg_filenames[i]
        extracted_df.at[i, 'seg_file_path'] = seg_files[i]
        extracted_df.at[i, 'ismanual'] = ismanual
        extracted_df.at[i, 'flows0'] = flow_i[0]
        extracted_df.at[i, 'flows1'] = flow_i[1]
        extracted_df.at[i, 'flows2'] = flow_i[2]
        extracted_df.at[i, 'flows3'] = flow_i[3]
        extracted_df.at[i, 'flows4'] = flow_i[4]
        extracted_df.at[i, 'outlines'] = outlines_i
        extracted_df.at[i, 'masks'] = masks_i
        extracted_df.at[i, 'diameter_estimate_used_px'] = diameter_estimate_used_px_i
        # Image-wise calculated properties
        extracted_df.at[i, 'diameter_training_px'] = final_diameter_training_px
        extracted_df.at[i, 'CP_out_diameter_mean_px'] = CP_out_diameter_mean_px_i # from Cellpose output diameter distribution
        extracted_df.at[i, 'CP_out_diameter_median_px'] = CP_out_diameter_median_px_i # from Cellpose output diameter distribution
        extracted_df.at[i, 'CP_out_diameter_distribution_px'] = CP_out_diameter_array_px_i # from Cellpose output diameter distribution
        extracted_df.at[i, 'N_cells'] = N_cells_i
        extracted_df.at[i, 'A_image_px2'] = A_image_px2
        extracted_df.at[i, 'A_empty_px2'] = A_empty_px2
        extracted_df.at[i, 'A_SF_px2'] = A_SF_px2
        extracted_df.at[i, 'Ar_px2_SFperimage'] = Ar_px2_SFperimage
        extracted_df.at[i, 'D_SF_px'] = D_SF_px
        extracted_df.at[i, 'R_SF_px'] = R_SF_px
        extracted_df.at[i, 'A_CP_mask_px2'] = A_CP_mask_px2
        extracted_df.at[i, 'Ar_px2_CP_maskperImage'] = Ar_px2_CP_maskperImage
        extracted_df.at[i, 'Ar_px2_CP_maskperSF'] = Ar_px2_CP_maskperSF
        # from Cell-wise calculated properties      
        extracted_df.at[i, 'A_cell_distribution_px2'] = np.array(A_cell_distribution_px2)
        extracted_df.at[i, 'd_cell_distribution_px'] = np.array(d_cell_distribution_px)
        extracted_df.at[i, 'centroid_x_distribution_px'] = np.array(centroid_x_distribution_px)
        extracted_df.at[i, 'centroid_y_distribution_px'] = np.array(centroid_y_distribution_px)
        extracted_df.at[i, 'd_cell_mean_px'] = d_cell_mean_px
        extracted_df.at[i, 'A_cell_mean_px2'] = A_cell_mean_px2
        extracted_df.at[i, 'd_cell_median_px'] = d_cell_median_px
        extracted_df.at[i, 'A_cell_median_px2'] = A_cell_median_px2


    # After the loop, ensure the DataFrame is properly indexed
    extracted_df = extracted_df.reset_index(drop=True)  # Reset index to ensure it starts at 0 and is continuous
    
    # Clean CP_out_diameter_distribution_px after the loop
    extracted_df['CP_out_diameter_distribution_px'] = extracted_df['CP_out_diameter_distribution_px'].apply(
        lambda x: np.array([x]) if isinstance(x, np.ndarray) and x.ndim == 0 else x
    )

    # Print columns that have None values
    none_columns = extracted_df.columns[extracted_df.isnull().any()].tolist()
    print(f"NB: Columns with None/NaN values after extraction: {none_columns}") if CP_extract_log_level >= 1 else None


    #################################################### Save Data

    print(f"\n Saving data \n")

    ### Save Extracted DataFrame
    csv_filename = 'extracted_DataFrame.csv'
    extracted_df.to_csv(os.path.join(output_dir, csv_filename), sep='\t', index=False)
    print(f"Saved extracted DataFrame to {csv_filename}") if CP_extract_log_level >= 1 else None

    # Save DataFrame to Pickle (Primary input for CP_dimentionalise_1)
    pickle_filename = 'extracted_DataFrame.pkl'
    extracted_df.to_pickle(os.path.join(output_dir, pickle_filename))
    print(f"Saved extracted DataFrame to {pickle_filename}") if CP_extract_log_level >= 1 else None

    # # Save DataFrame to Excel (useful for manual inspection)
    # excel_filename = 'extracted_DataFrame.xlsx'
    # try:
    #     # Convert complex objects like numpy arrays to strings for Excel compatibility
    #     df_for_excel = extracted_df.copy()
    #     for col in df_for_excel.columns:
    #         print(f"Saving to excel: Checking column: {col}") if CP_extract_log_level >= 2 else None
    #         if df_for_excel[col].apply(lambda x: isinstance(x, np.ndarray)).any():
    #             df_for_excel[col] = df_for_excel[col].apply(lambda x: str(x.tolist()) if isinstance(x, np.ndarray) else x) # Convert arrays to string representation of list
    #     df_for_excel.to_excel(os.path.join(output_dir, excel_filename), index=False)
    #     print(f"Saved extracted DataFrame to {excel_filename}") if CP_extract_log_level >= 1 else None

    # except Exception as e:
    #     print(f"Warning: Could not save extracted data to Excel format. Error: {e}")
    #     print("Excel format might not support complex data types like numpy arrays stored in the DataFrame.")



    #################################################### return
    return output_dir # Format_1 requires output_dir as first return

# Example usage:
if __name__ == "__main__":
    print("Running CP extract...")
    
    CP_extract_1(
        # Segmentation output_dir of hot 3000px States 79 and 100
        input_dir=r"C:\Users\obs\OneDrive\ETH\ETH_MSc\Masters Thesis\CIPS_variations\20250604_1311111\20250604_1312276\20250604_1312276\20250604_1313140",
        output_dir_comment="test new CP_extract_1",
        CP_extract_log_level=1,
        save_flows=0
    )